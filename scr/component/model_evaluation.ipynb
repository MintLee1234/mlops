{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score,\n",
    "                              classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve)\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bc9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def predictions(self, model, X_val_transformed):\n",
    "        y_pred = model.predict(X_val_transformed)\n",
    "        y_pred_proba = model.predict_proba(X_val_transformed)  # For ROC-AUC and PR-AUC\n",
    "        return y_pred, y_pred_proba\n",
    "\n",
    "    def model_evaluation(self, y_val, y_pred, y_pred_proba):\n",
    "        # Evaluation metrics\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred, average='weighted')\n",
    "        recall = recall_score(y_val, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba, multi_class='ovr', average='weighted')\n",
    "        pr_auc = average_precision_score(y_val, y_pred_proba, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "        # Print detailed classification report and confusion matrix\n",
    "        print(\"Classification Report:\\n\", classification_report(y_val, y_pred))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "        \n",
    "        # Return evaluation metrics\n",
    "        return accuracy, precision, recall, f1, roc_auc, pr_auc\n",
    "\n",
    "    def plot_roc_curve(self, y_val, y_pred_proba):\n",
    "        # Binarize the output\n",
    "        y_val_bin = label_binarize(y_val, classes=np.unique(y_val))\n",
    "        n_classes = y_val_bin.shape[1]\n",
    "        \n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_pred_proba[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Plot ROC curve for each class\n",
    "        plt.figure()\n",
    "        for i in range(n_classes):\n",
    "            plt.plot(fpr[i], tpr[i], label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(os.path.join(self.config.root_dir, 'roc_curve.png'))\n",
    "        plt.close()\n",
    "\n",
    "    def plot_pr_curve(self, y_val, y_pred_proba):\n",
    "        # Binarize the output\n",
    "        y_val_bin = label_binarize(y_val, classes=np.unique(y_val))\n",
    "        n_classes = y_val_bin.shape[1]\n",
    "        \n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        pr_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(y_val_bin[:, i], y_pred_proba[:, i])\n",
    "            pr_auc[i] = auc(recall[i], precision[i])\n",
    "\n",
    "        # Plot Precision-Recall curve for each class\n",
    "        plt.figure()\n",
    "        for i in range(n_classes):\n",
    "            plt.plot(recall[i], precision[i], label=f'Class {i} (area = {pr_auc[i]:0.2f})')\n",
    "        \n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(os.path.join(self.config.root_dir, 'pr_curve.png'))\n",
    "        plt.close()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
