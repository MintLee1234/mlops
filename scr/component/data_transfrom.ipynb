{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from src.churn import logging\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.train, self.test = train_test_split(self.df, test_size=0.7, random_state=42)\n",
    "    def transform_data(df):\n",
    "        \"\"\"\n",
    "        Performs data transformations on the input DataFrame.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert data to appropriate dtypes\n",
    "        numerical_columns = ['age', 'days_since_last_login', 'avg_time_spent',\n",
    "                            'avg_transaction_value', 'avg_frequency_login_days', 'points_in_wallet', 'churn_risk_score']\n",
    "        df[numerical_columns] = df[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "        df['last_visit_time'] = pd.to_datetime(df['last_visit_time'], format='%H:%M:%S')\n",
    "        categorical_columns = ['gender', 'region_category', 'membership_category',\n",
    "                            'joined_through_referral', 'preferred_offer_types', 'medium_of_operation',\n",
    "                            'internet_option', 'used_special_discount', 'offer_application_preference',\n",
    "                            'past_complaint', 'complaint_status', 'feedback']\n",
    "        df[categorical_columns] = df[categorical_columns].astype('object')\n",
    "        df['joining_date'] = pd.to_datetime(df['joining_date'])\n",
    "\n",
    "        # Impute missing values\n",
    "        # Iterative Imputer for numerical columns\n",
    "        target_column = 'churn_risk_score'\n",
    "        numeric_columns = df.select_dtypes(include='number').columns.drop(target_column)\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = df.copy()\n",
    "        df_scaled[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "        iterative_imputer = IterativeImputer(random_state=42)\n",
    "        df_scaled[numeric_columns] = iterative_imputer.fit_transform(df_scaled[numeric_columns])\n",
    "        df[numeric_columns] = scaler.inverse_transform(df_scaled[numeric_columns])\n",
    "\n",
    "        # KNN Imputer for categorical columns\n",
    "        df['gender'] = df['gender'].replace('Unknown', np.nan)\n",
    "        categorical_columns = ['gender', 'region_category', 'joined_through_referral', 'medium_of_operation',\n",
    "                            'preferred_offer_types']\n",
    "        encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "        encoder.fit(df[categorical_columns])\n",
    "        df[categorical_columns] = encoder.transform(df[categorical_columns])\n",
    "        imputer = KNNImputer(n_neighbors=5, metric='nan_euclidean', weights='distance')\n",
    "        df[categorical_columns] = imputer.fit_transform(df[categorical_columns])\n",
    "        for col in categorical_columns:\n",
    "            df[col] = df[col].astype('object')\n",
    "\n",
    "        # Feature Engineering\n",
    "        specific_date = datetime(2024, 5, 17)\n",
    "        df['tenure_months'] = ((specific_date.year - df['joining_date'].dt.year) * 12 +\n",
    "                            (specific_date.month - df['joining_date'].dt.month)).astype('int64')\n",
    "        df['visit_hour'] = df['last_visit_time'].dt.hour.astype('int64')\n",
    "        df['login_spend_ratio'] = df['avg_time_spent'] / df['avg_frequency_login_days']\n",
    "        df['login_transaction_ratio'] = df['avg_frequency_login_days'] / df['avg_transaction_value']\n",
    "\n",
    "        # Target column class distribution\n",
    "        mapping = {\n",
    "            -1: 0,\n",
    "            0: 0,\n",
    "            2: 0,\n",
    "            3: 1,\n",
    "            4: 2,\n",
    "            5: 2\n",
    "        }\n",
    "\n",
    "        df['churn_risk_score'] = df['churn_risk_score'].map(mapping)\n",
    "\n",
    "        df = df.drop(columns=['joining_date', 'last_visit_time'])\n",
    "\n",
    "        # Rename columns\n",
    "        rename_mapping = {\n",
    "            'avg_frequency_login_days': 'frequency',\n",
    "            'avg_transaction_value': 'monetary',\n",
    "            'days_since_last_login': 'recency'\n",
    "        }\n",
    "\n",
    "        df = df.rename(columns=rename_mapping)\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
